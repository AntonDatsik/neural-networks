{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №6. Применение сверточных нейронных сетей (многоклассовая классификация)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "Загрузите данные. Разделите исходный набор данных на обучающую и валидационную выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = os.path.join('data', 'sign-language-mnist')\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(dataset_path, 'sign_mnist_train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(dataset_path, 'sign_mnist_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = train_data['label'].values\n",
    "train_data.drop(columns='label', inplace=True)\n",
    "X_train = train_data.values\n",
    "\n",
    "y_test = test_data['label'].values\n",
    "test_data.drop(columns='label', inplace=True)\n",
    "X_test = test_data.values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_val = X_val.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "Реализуйте глубокую нейронную сеть со сверточными слоями. Какое качество классификации получено? Какая архитектура сети была использована?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 24)                6168      \n",
      "=================================================================\n",
      "Total params: 232,088\n",
      "Trainable params: 231,128\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Activation, BatchNormalization, Dropout, Flatten\n",
    "\n",
    "network = Sequential([\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "network.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_categorial из keras работает не совсем так как нужно, у нас классы от 0 до 25, но нет 9-го класса.\n",
    "# И он возвращает матрицу из 25 столбцов(в 9 столбце у всех нули), а должно быть по логике вещей 24.\n",
    "\n",
    "def to_categorial_v2(y):\n",
    "    y_set = set(y)\n",
    "    y_uniq_ordered_list = sorted(list(y_set))\n",
    "    num_classes = len(y_set)\n",
    "    classes_mtx = np.zeros((len(y), num_classes))\n",
    "    for i, label in enumerate(y):\n",
    "        j = y_uniq_ordered_list.index(label)\n",
    "        classes_mtx[i][j] = 1\n",
    "\n",
    "    return classes_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_data_generator(X, y):\n",
    "    gen = ImageDataGenerator(rescale=1/255.)\n",
    "    return gen.flow(\n",
    "        X,\n",
    "        to_categorial_v2(y),\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "train_gen = get_data_generator(X_train, y_train)\n",
    "val_gen = get_data_generator(X_val, y_val)\n",
    "test_gen = get_data_generator(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21964, 24)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorial_v2(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 344 steps, validate for 86 steps\n",
      "Epoch 1/20\n",
      "344/344 [==============================] - 3s 8ms/step - loss: 1.4013 - accuracy: 0.5888 - val_loss: 1.9005 - val_accuracy: 0.3566\n",
      "Epoch 2/20\n",
      "344/344 [==============================] - 2s 6ms/step - loss: 0.2979 - accuracy: 0.9017 - val_loss: 0.0507 - val_accuracy: 0.9945\n",
      "Epoch 3/20\n",
      "344/344 [==============================] - 2s 6ms/step - loss: 0.1198 - accuracy: 0.9654 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 4/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0614 - accuracy: 0.9835 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "344/344 [==============================] - 2s 6ms/step - loss: 0.0393 - accuracy: 0.9900 - val_loss: 6.3062e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "344/344 [==============================] - 2s 6ms/step - loss: 0.0315 - accuracy: 0.9914 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 7/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
      "Epoch 8/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "344/344 [==============================] - 2s 6ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.0055 - val_accuracy: 0.9987\n",
      "Epoch 10/20\n",
      "344/344 [==============================] - 2s 6ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 4.0305e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
      "Epoch 13/20\n",
      "344/344 [==============================] - 2s 6ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0395 - val_accuracy: 0.9898\n",
      "Epoch 14/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 1.7221e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 4.1574e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0149 - val_accuracy: 0.9964\n",
      "Epoch 17/20\n",
      "344/344 [==============================] - 2s 6ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 8.8629e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1171 - val_accuracy: 0.9652\n",
      "Epoch 19/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0933 - val_accuracy: 0.9683\n",
      "Epoch 20/20\n",
      "344/344 [==============================] - 2s 5ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 3.9315e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f46bc1ab630>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(\n",
    "    train_gen, \n",
    "    epochs=20,\n",
    "    validation_data=val_gen,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06638175332135793, 0.9820134]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.\n",
    "Примените дополнение данных (data augmentation). Как это повлияло на качество классификатора?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def get_augmented_data_generator(X, y):\n",
    "    gen = ImageDataGenerator(\n",
    "        rotation_range=0.15,\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05\n",
    "    )\n",
    "    \n",
    "    return gen.flow(\n",
    "        X,\n",
    "        to_categorial_v2(y),\n",
    "        batch_size=64,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "\n",
    "train_gen = get_augmented_data_generator(X_train, y_train)\n",
    "val_gen = get_augmented_data_generator(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 24)                6168      \n",
      "=================================================================\n",
      "Total params: 232,088\n",
      "Trainable params: 231,128\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Activation, BatchNormalization, Dropout, Flatten\n",
    "\n",
    "network = Sequential([\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "network.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 344 steps, validate for 86 steps\n",
      "Epoch 1/50\n",
      "344/344 [==============================] - 6s 17ms/step - loss: 2.1027 - accuracy: 0.3920 - val_loss: 2.7312 - val_accuracy: 0.2227\n",
      "Epoch 2/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.8505 - accuracy: 0.7076 - val_loss: 0.3802 - val_accuracy: 0.9029\n",
      "Epoch 3/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.4969 - accuracy: 0.8307 - val_loss: 0.2604 - val_accuracy: 0.9210\n",
      "Epoch 4/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.3262 - accuracy: 0.8897 - val_loss: 0.1058 - val_accuracy: 0.9729\n",
      "Epoch 5/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.2367 - accuracy: 0.9199 - val_loss: 0.0947 - val_accuracy: 0.9754\n",
      "Epoch 6/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.1870 - accuracy: 0.9351 - val_loss: 0.4100 - val_accuracy: 0.8661\n",
      "Epoch 7/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.1507 - accuracy: 0.9495 - val_loss: 0.0510 - val_accuracy: 0.9880\n",
      "Epoch 8/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.1362 - accuracy: 0.9551 - val_loss: 0.0321 - val_accuracy: 0.9913\n",
      "Epoch 9/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.1134 - accuracy: 0.9624 - val_loss: 0.0171 - val_accuracy: 0.9962\n",
      "Epoch 10/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.1076 - accuracy: 0.9634 - val_loss: 0.0432 - val_accuracy: 0.9902\n",
      "Epoch 11/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0934 - accuracy: 0.9692 - val_loss: 0.1330 - val_accuracy: 0.9603\n",
      "Epoch 12/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0864 - accuracy: 0.9700 - val_loss: 0.0329 - val_accuracy: 0.9911\n",
      "Epoch 13/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0764 - accuracy: 0.9745 - val_loss: 0.0532 - val_accuracy: 0.9860\n",
      "Epoch 14/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0720 - accuracy: 0.9768 - val_loss: 0.1449 - val_accuracy: 0.9508\n",
      "Epoch 15/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0740 - accuracy: 0.9757 - val_loss: 0.0159 - val_accuracy: 0.9962\n",
      "Epoch 16/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0664 - accuracy: 0.9769 - val_loss: 0.8743 - val_accuracy: 0.7969\n",
      "Epoch 17/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0621 - accuracy: 0.9786 - val_loss: 0.0170 - val_accuracy: 0.9945\n",
      "Epoch 18/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0578 - accuracy: 0.9806 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
      "Epoch 19/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0520 - accuracy: 0.9833 - val_loss: 0.0212 - val_accuracy: 0.9942\n",
      "Epoch 20/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0533 - accuracy: 0.9819 - val_loss: 0.0067 - val_accuracy: 0.9976\n",
      "Epoch 21/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0499 - accuracy: 0.9828 - val_loss: 0.0056 - val_accuracy: 0.9985\n",
      "Epoch 22/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0507 - accuracy: 0.9827 - val_loss: 0.0090 - val_accuracy: 0.9978\n",
      "Epoch 23/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0474 - accuracy: 0.9833 - val_loss: 0.0172 - val_accuracy: 0.9951\n",
      "Epoch 24/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0446 - accuracy: 0.9851 - val_loss: 0.0267 - val_accuracy: 0.9916\n",
      "Epoch 25/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0431 - accuracy: 0.9851 - val_loss: 0.1419 - val_accuracy: 0.9534\n",
      "Epoch 26/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0450 - accuracy: 0.9860 - val_loss: 0.0114 - val_accuracy: 0.9967\n",
      "Epoch 27/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.0023 - val_accuracy: 0.9995\n",
      "Epoch 28/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0427 - accuracy: 0.9854 - val_loss: 0.0503 - val_accuracy: 0.9854\n",
      "Epoch 29/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0419 - accuracy: 0.9857 - val_loss: 0.6926 - val_accuracy: 0.7800\n",
      "Epoch 30/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0432 - accuracy: 0.9860 - val_loss: 0.0562 - val_accuracy: 0.9791\n",
      "Epoch 31/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0403 - accuracy: 0.9868 - val_loss: 0.0829 - val_accuracy: 0.9716\n",
      "Epoch 32/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.1580 - val_accuracy: 0.9608\n",
      "Epoch 33/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.0181 - val_accuracy: 0.9931\n",
      "Epoch 34/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 0.0537 - val_accuracy: 0.9840\n",
      "Epoch 35/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.2119 - val_accuracy: 0.9272\n",
      "Epoch 36/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 0.0291 - val_accuracy: 0.9891\n",
      "Epoch 37/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.0016 - val_accuracy: 0.9991\n",
      "Epoch 38/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0304 - val_accuracy: 0.9905\n",
      "Epoch 39/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0319 - accuracy: 0.9889 - val_loss: 5.4054e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
      "Epoch 41/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 42/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0330 - accuracy: 0.9892 - val_loss: 0.1170 - val_accuracy: 0.9683\n",
      "Epoch 43/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0347 - accuracy: 0.9887 - val_loss: 0.0028 - val_accuracy: 0.9987\n",
      "Epoch 44/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 45/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0279 - accuracy: 0.9906 - val_loss: 2.1696e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0288 - accuracy: 0.9904 - val_loss: 2.1583e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.0620 - val_accuracy: 0.9814\n",
      "Epoch 48/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 0.0239 - val_accuracy: 0.9913\n",
      "Epoch 49/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.0406 - val_accuracy: 0.9856\n",
      "Epoch 50/50\n",
      "344/344 [==============================] - 5s 15ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.1141 - val_accuracy: 0.9639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f431ffa99b0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(\n",
    "    train_gen, \n",
    "    epochs=50,\n",
    "    validation_data=val_gen,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6653488172894031, 0.8773006]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.\n",
    "Поэкспериментируйте с готовыми нейронными сетями (например, AlexNet, VGG16, Inception и т.п.), применив передаточное обучение. Как это повлияло на качество классификатора? Можно ли было обойтись без него?\n",
    "Какой максимальный результат удалось получить на контрольной выборке?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_data_for_vgg19(data):\n",
    "    # 3 канала и расширяем до 32 размер картинки\n",
    "    return np.pad(\n",
    "        np.concatenate([data, data, data], axis=-1),\n",
    "        ((0, 0), (2, 2), (2, 2), (0, 0)), mode='constant'\n",
    "    )\n",
    "\n",
    "X_train_adjusted = adjust_data_for_vgg19(X_train)\n",
    "X_val_adjusted = adjust_data_for_vgg19(X_val)\n",
    "X_test_adjusted = adjust_data_for_vgg19(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 24)                12312     \n",
      "=================================================================\n",
      "Total params: 20,299,352\n",
      "Trainable params: 12,074,008\n",
      "Non-trainable params: 8,225,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "pre_trained_network = VGG19(input_shape=(32, 32, 3), include_top=False, weights=\"imagenet\")\n",
    "    \n",
    "for layer in pre_trained_network.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in pre_trained_network.layers[15:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "last_layer = pre_trained_network.get_layer('block5_pool')\n",
    "last_output = last_layer.output\n",
    "    \n",
    "x = GlobalAveragePooling2D()(last_output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(24, activation='softmax')(x)\n",
    "\n",
    "network = Model(pre_trained_network.input, x)\n",
    "\n",
    "network.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = get_data_generator(X_train_adjusted, y_train)\n",
    "val_gen = get_data_generator(X_val_adjusted, y_val)\n",
    "test_gen = get_data_generator(X_test_adjusted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 344 steps, validate for 86 steps\n",
      "Epoch 1/20\n",
      "344/344 [==============================] - 12s 35ms/step - loss: 2.7378 - accuracy: 0.2033 - val_loss: 1.7463 - val_accuracy: 0.5336\n",
      "Epoch 2/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 1.4406 - accuracy: 0.5355 - val_loss: 0.7759 - val_accuracy: 0.7849\n",
      "Epoch 3/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.8423 - accuracy: 0.7164 - val_loss: 0.4452 - val_accuracy: 0.8758\n",
      "Epoch 4/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.5513 - accuracy: 0.8139 - val_loss: 0.2971 - val_accuracy: 0.9168\n",
      "Epoch 5/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.3935 - accuracy: 0.8716 - val_loss: 0.1887 - val_accuracy: 0.9554\n",
      "Epoch 6/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.3024 - accuracy: 0.9011 - val_loss: 0.1432 - val_accuracy: 0.9685\n",
      "Epoch 7/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.2240 - accuracy: 0.9303 - val_loss: 0.0956 - val_accuracy: 0.9792\n",
      "Epoch 8/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.1821 - accuracy: 0.9443 - val_loss: 0.0744 - val_accuracy: 0.9883\n",
      "Epoch 9/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.1467 - accuracy: 0.9571 - val_loss: 0.0561 - val_accuracy: 0.9913\n",
      "Epoch 10/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.1123 - accuracy: 0.9691 - val_loss: 0.0405 - val_accuracy: 0.9938\n",
      "Epoch 11/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.0925 - accuracy: 0.9741 - val_loss: 0.0286 - val_accuracy: 0.9969\n",
      "Epoch 12/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.0824 - accuracy: 0.9770 - val_loss: 0.0256 - val_accuracy: 0.9969\n",
      "Epoch 13/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.0686 - accuracy: 0.9824 - val_loss: 0.0168 - val_accuracy: 0.9987\n",
      "Epoch 14/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.0609 - accuracy: 0.9843 - val_loss: 0.0221 - val_accuracy: 0.9958\n",
      "Epoch 15/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.0510 - accuracy: 0.9885 - val_loss: 0.0174 - val_accuracy: 0.9982\n",
      "Epoch 16/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.0463 - accuracy: 0.9888 - val_loss: 0.0112 - val_accuracy: 0.9989\n",
      "Epoch 17/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.0431 - accuracy: 0.9890 - val_loss: 0.0091 - val_accuracy: 0.9991\n",
      "Epoch 18/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.0330 - accuracy: 0.9929 - val_loss: 0.0083 - val_accuracy: 0.9991\n",
      "Epoch 19/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.0289 - accuracy: 0.9945 - val_loss: 0.0093 - val_accuracy: 0.9985\n",
      "Epoch 20/20\n",
      "344/344 [==============================] - 12s 34ms/step - loss: 0.0265 - accuracy: 0.9950 - val_loss: 0.0098 - val_accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f42fe45b198>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(\n",
    "    train_gen, \n",
    "    epochs=20,\n",
    "    validation_data=val_gen,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 2s 20ms/step - loss: 0.0563 - accuracy: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05627798751425163, 0.9821528]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
