{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №5. Применение сверточных нейронных сетей (бинарная классификация)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "Загрузите данные. Разделите исходный набор данных на обучающую, валидационную и контрольную выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачиваем данные ручками и ложим в data директорию, где хранятся датасеты из всех лабораторных.\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = os.path.join('data', 'dogs-vs-cats')\n",
    "\n",
    "data = [[os.path.basename(filename), 'dog' if 'dog' in filename else 'cat']\n",
    "        for filename in os.listdir(os.path.join(dataset_path, 'train'))]\n",
    "\n",
    "data_df = pd.DataFrame(data=data, columns=['filename', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 2), (4000, 2), (1000, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, validate_df = train_test_split(data_df, test_size=0.2, random_state=42)\n",
    "validate_df, test_df = train_test_split(validate_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "train_df.shape, validate_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "Реализуйте глубокую нейронную сеть с как минимум тремя сверточными слоями. Какое качество классификации получено?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 62, 62, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 29, 29, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 12,942,273\n",
      "Trainable params: 12,940,801\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Activation, BatchNormalization, Dropout, Flatten\n",
    "\n",
    "\n",
    "network = Sequential([\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "network.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])    \n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 4000 validated image filenames belonging to 2 classes.\n",
      "Found 1000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_data_generator(df):\n",
    "    img_h, img_w = 128, 128\n",
    "    gen = ImageDataGenerator(rescale=1./ 255)\n",
    "    return gen.flow_from_dataframe(\n",
    "        df, \n",
    "        'data/dogs-vs-cats/train/', \n",
    "        x_col='filename',\n",
    "        y_col='label',\n",
    "        target_size=(img_w, img_h),\n",
    "        class_mode='binary',\n",
    "        batch_size=128\n",
    "    )\n",
    "\n",
    "train_gen = get_data_generator(train_df)\n",
    "valid_gen = get_data_generator(validate_df)\n",
    "test_gen = get_data_generator(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 157 steps, validate for 32 steps\n",
      "Epoch 1/15\n",
      "157/157 [==============================] - 51s 322ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.6458 - val_accuracy: 0.8605\n",
      "Epoch 2/15\n",
      "157/157 [==============================] - 50s 321ms/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.6492 - val_accuracy: 0.8490\n",
      "Epoch 3/15\n",
      "157/157 [==============================] - 50s 321ms/step - loss: 0.0226 - accuracy: 0.9918 - val_loss: 0.5901 - val_accuracy: 0.8695\n",
      "Epoch 4/15\n",
      "157/157 [==============================] - 50s 321ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.6021 - val_accuracy: 0.8683\n",
      "Epoch 5/15\n",
      "157/157 [==============================] - 50s 321ms/step - loss: 0.0254 - accuracy: 0.9902 - val_loss: 0.5575 - val_accuracy: 0.8767\n",
      "Epoch 6/15\n",
      "157/157 [==============================] - 50s 321ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.6220 - val_accuracy: 0.8593\n",
      "Epoch 7/15\n",
      "157/157 [==============================] - 50s 322ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.8014 - val_accuracy: 0.8207\n",
      "Epoch 8/15\n",
      "157/157 [==============================] - 50s 321ms/step - loss: 0.0338 - accuracy: 0.9879 - val_loss: 0.5816 - val_accuracy: 0.8503\n",
      "Epoch 9/15\n",
      "157/157 [==============================] - 50s 321ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.6662 - val_accuracy: 0.8528\n",
      "Epoch 10/15\n",
      "157/157 [==============================] - 50s 322ms/step - loss: 0.0214 - accuracy: 0.9923 - val_loss: 0.6237 - val_accuracy: 0.8583\n",
      "Epoch 11/15\n",
      "157/157 [==============================] - 50s 321ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.6991 - val_accuracy: 0.8590\n",
      "Epoch 12/15\n",
      "157/157 [==============================] - 50s 322ms/step - loss: 0.0170 - accuracy: 0.9936 - val_loss: 0.5505 - val_accuracy: 0.8800\n",
      "Epoch 13/15\n",
      "157/157 [==============================] - 50s 322ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.5891 - val_accuracy: 0.8665\n",
      "Epoch 14/15\n",
      "157/157 [==============================] - 51s 322ms/step - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.9535 - val_accuracy: 0.8253\n",
      "Epoch 15/15\n",
      "157/157 [==============================] - 50s 322ms/step - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.6468 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a14693780>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(\n",
    "    train_gen, \n",
    "    epochs=15,\n",
    "    validation_data=valid_gen,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 224ms/step - loss: 0.6267 - accuracy: 0.8560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.626665111631155, 0.856]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.\n",
    "Примените дополнение данных (data augmentation). Как это повлияло на качество классификатора?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 4000 validated image filenames belonging to 2 classes.\n",
      "Found 1000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def get_augmented_data_generator(df):\n",
    "    img_h, img_w = 128, 128\n",
    "\n",
    "    gen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )\n",
    "    \n",
    "    return gen.flow_from_dataframe(\n",
    "        df, \n",
    "        'data/dogs-vs-cats/train/', \n",
    "        x_col='filename',\n",
    "        y_col='label',\n",
    "        target_size=(img_w, img_h),\n",
    "        class_mode='binary',\n",
    "        batch_size=64\n",
    "    )\n",
    "\n",
    "\n",
    "train_augmented_gen = get_augmented_data_generator(train_df)\n",
    "valid_augmented_gen = get_augmented_data_generator(validate_df)\n",
    "test_augmented_gen = get_augmented_data_generator(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 62, 62, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 62, 62, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 29, 29, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 29, 29, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 12,942,273\n",
      "Trainable params: 12,940,801\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Activation, BatchNormalization, Dropout, Flatten\n",
    "\n",
    "\n",
    "network = Sequential([\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "network.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])    \n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 313 steps, validate for 63 steps\n",
      "Epoch 1/50\n",
      "313/313 [==============================] - 98s 313ms/step - loss: 0.7422 - accuracy: 0.6355 - val_loss: 0.8462 - val_accuracy: 0.5060\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.5807 - accuracy: 0.7059 - val_loss: 0.5608 - val_accuracy: 0.7135\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.5156 - accuracy: 0.7459 - val_loss: 0.4792 - val_accuracy: 0.7715\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.4706 - accuracy: 0.7729 - val_loss: 0.5134 - val_accuracy: 0.7477\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.4390 - accuracy: 0.7952 - val_loss: 0.4884 - val_accuracy: 0.7645\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.4158 - accuracy: 0.8102 - val_loss: 0.4993 - val_accuracy: 0.7665\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.3895 - accuracy: 0.8218 - val_loss: 0.4161 - val_accuracy: 0.8130\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.3704 - accuracy: 0.8328 - val_loss: 0.5016 - val_accuracy: 0.7635\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.3541 - accuracy: 0.8432 - val_loss: 0.3928 - val_accuracy: 0.8328\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.3375 - accuracy: 0.8514 - val_loss: 0.5112 - val_accuracy: 0.7872\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.3263 - accuracy: 0.8539 - val_loss: 0.4556 - val_accuracy: 0.8175\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.3175 - accuracy: 0.8609 - val_loss: 0.3888 - val_accuracy: 0.8425\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.3071 - accuracy: 0.8652 - val_loss: 0.3873 - val_accuracy: 0.8253\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2986 - accuracy: 0.8723 - val_loss: 0.3154 - val_accuracy: 0.8655\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2936 - accuracy: 0.8718 - val_loss: 0.3822 - val_accuracy: 0.8315\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2824 - accuracy: 0.8803 - val_loss: 0.5765 - val_accuracy: 0.7795\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2738 - accuracy: 0.8812 - val_loss: 0.3157 - val_accuracy: 0.8630\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2694 - accuracy: 0.8866 - val_loss: 0.3307 - val_accuracy: 0.8610\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2669 - accuracy: 0.8868 - val_loss: 0.3755 - val_accuracy: 0.8278\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2606 - accuracy: 0.8884 - val_loss: 0.2619 - val_accuracy: 0.8848\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2582 - accuracy: 0.8925 - val_loss: 0.3721 - val_accuracy: 0.8440\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2504 - accuracy: 0.8940 - val_loss: 0.2776 - val_accuracy: 0.8852\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2500 - accuracy: 0.8950 - val_loss: 0.3032 - val_accuracy: 0.8720\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2445 - accuracy: 0.8978 - val_loss: 0.2603 - val_accuracy: 0.8903\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2440 - accuracy: 0.8958 - val_loss: 0.4259 - val_accuracy: 0.8275\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2371 - accuracy: 0.8999 - val_loss: 0.2755 - val_accuracy: 0.8805\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2313 - accuracy: 0.9018 - val_loss: 0.3484 - val_accuracy: 0.8518\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 97s 309ms/step - loss: 0.2284 - accuracy: 0.9025 - val_loss: 0.2584 - val_accuracy: 0.8970\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2281 - accuracy: 0.9044 - val_loss: 0.3338 - val_accuracy: 0.8615\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2196 - accuracy: 0.9075 - val_loss: 0.4062 - val_accuracy: 0.8313\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2137 - accuracy: 0.9112 - val_loss: 0.2316 - val_accuracy: 0.9022\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2210 - accuracy: 0.9096 - val_loss: 0.2650 - val_accuracy: 0.8923\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2181 - accuracy: 0.9075 - val_loss: 0.2253 - val_accuracy: 0.9040\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 97s 309ms/step - loss: 0.2147 - accuracy: 0.9094 - val_loss: 0.2447 - val_accuracy: 0.8960\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2233 - accuracy: 0.9064 - val_loss: 0.2689 - val_accuracy: 0.8825\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2090 - accuracy: 0.9144 - val_loss: 0.2290 - val_accuracy: 0.9100\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2051 - accuracy: 0.9166 - val_loss: 0.3211 - val_accuracy: 0.8577\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2065 - accuracy: 0.9129 - val_loss: 0.2109 - val_accuracy: 0.9122\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2018 - accuracy: 0.9147 - val_loss: 0.2357 - val_accuracy: 0.9062\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2041 - accuracy: 0.9162 - val_loss: 0.4271 - val_accuracy: 0.8270\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.1973 - accuracy: 0.9190 - val_loss: 0.3112 - val_accuracy: 0.8748\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.1924 - accuracy: 0.9205 - val_loss: 0.1914 - val_accuracy: 0.9185\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.1880 - accuracy: 0.9226 - val_loss: 0.2267 - val_accuracy: 0.8975\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.1877 - accuracy: 0.9214 - val_loss: 0.2351 - val_accuracy: 0.9020\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.1962 - accuracy: 0.9208 - val_loss: 0.3568 - val_accuracy: 0.8503\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.1943 - accuracy: 0.9188 - val_loss: 0.2479 - val_accuracy: 0.9010\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.1882 - accuracy: 0.9225 - val_loss: 0.2127 - val_accuracy: 0.9128\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.1983 - accuracy: 0.9168 - val_loss: 0.2100 - val_accuracy: 0.9133\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.1883 - accuracy: 0.9207 - val_loss: 0.2615 - val_accuracy: 0.8953\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.1777 - accuracy: 0.9280 - val_loss: 0.2812 - val_accuracy: 0.9035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f35f423d278>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(\n",
    "    train_augmented_gen,\n",
    "    epochs=50,\n",
    "    validation_data=valid_augmented_gen,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 237ms/step - loss: 0.3057 - accuracy: 0.9070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3057435564696789, 0.907]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(test_augmented_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 256ms/step - loss: 0.2618 - accuracy: 0.9100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26183051988482475, 0.91]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как видим точность выше примерно на 6 процентов на одной и той же контрольной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.\n",
    "Поэкспериментируйте с готовыми нейронными сетями (например, AlexNet, VGG16, Inception и т.п.), применив передаточное обучение. Как это повлияло на качество классификатора?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 20,287,553\n",
      "Trainable params: 12,062,209\n",
      "Non-trainable params: 8,225,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# В качестве готовой сети возьмем VGG19\n",
    "# https://keras.io/applications/#vgg19\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "image_size = 224\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "pre_trained_model = VGG19(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
    "    \n",
    "for layer in pre_trained_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in pre_trained_model.layers[15:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "last_layer = pre_trained_model.get_layer('block5_pool')\n",
    "last_output = last_layer.output\n",
    "    \n",
    "x = GlobalAveragePooling2D()(last_output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "network = Model(pre_trained_model.input, x)\n",
    "\n",
    "network.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 4000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "def get_data_generator(df):\n",
    "    gen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )\n",
    "    \n",
    "    return gen.flow_from_dataframe(\n",
    "        df, \n",
    "        'data/dogs-vs-cats/train/', \n",
    "        x_col='filename',\n",
    "        y_col='category',\n",
    "        target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "        class_mode='binary',\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "\n",
    "train_augmented_gen = get_augmented_data_generator(train_df)\n",
    "valid_augmented_gen = get_augmented_data_generator(validate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 313 steps, validate for 63 steps\n",
      "Epoch 1/20\n",
      "313/313 [==============================] - 124s 397ms/step - loss: 0.5481 - accuracy: 0.7224 - val_loss: 0.4328 - val_accuracy: 0.8048\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 125s 398ms/step - loss: 0.3914 - accuracy: 0.8300 - val_loss: 0.3425 - val_accuracy: 0.8490\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 125s 398ms/step - loss: 0.3159 - accuracy: 0.8660 - val_loss: 0.2867 - val_accuracy: 0.8742\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 124s 398ms/step - loss: 0.2761 - accuracy: 0.8849 - val_loss: 0.2578 - val_accuracy: 0.8945\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 124s 396ms/step - loss: 0.2545 - accuracy: 0.8955 - val_loss: 0.2761 - val_accuracy: 0.8790\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 124s 397ms/step - loss: 0.2415 - accuracy: 0.8999 - val_loss: 0.2190 - val_accuracy: 0.9085\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 124s 397ms/step - loss: 0.2219 - accuracy: 0.9069 - val_loss: 0.2277 - val_accuracy: 0.9053\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 125s 399ms/step - loss: 0.2127 - accuracy: 0.9141 - val_loss: 0.2209 - val_accuracy: 0.9120\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 125s 399ms/step - loss: 0.2013 - accuracy: 0.9194 - val_loss: 0.1928 - val_accuracy: 0.9235\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 125s 399ms/step - loss: 0.1923 - accuracy: 0.9216 - val_loss: 0.1899 - val_accuracy: 0.9247\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 124s 395ms/step - loss: 0.1860 - accuracy: 0.9243 - val_loss: 0.1982 - val_accuracy: 0.9158\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 125s 399ms/step - loss: 0.1782 - accuracy: 0.9271 - val_loss: 0.1887 - val_accuracy: 0.9210\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 125s 399ms/step - loss: 0.1789 - accuracy: 0.9262 - val_loss: 0.1832 - val_accuracy: 0.9260\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 125s 398ms/step - loss: 0.1703 - accuracy: 0.9320 - val_loss: 0.1677 - val_accuracy: 0.9315\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 125s 399ms/step - loss: 0.1601 - accuracy: 0.9370 - val_loss: 0.1717 - val_accuracy: 0.9315\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 125s 398ms/step - loss: 0.1580 - accuracy: 0.9382 - val_loss: 0.1608 - val_accuracy: 0.9333\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 125s 398ms/step - loss: 0.1565 - accuracy: 0.9374 - val_loss: 0.1633 - val_accuracy: 0.9337\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 125s 398ms/step - loss: 0.1465 - accuracy: 0.9406 - val_loss: 0.1538 - val_accuracy: 0.9400\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 125s 399ms/step - loss: 0.1447 - accuracy: 0.9423 - val_loss: 0.1842 - val_accuracy: 0.9227\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 125s 398ms/step - loss: 0.1434 - accuracy: 0.9431 - val_loss: 0.1520 - val_accuracy: 0.9385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36142ace80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(\n",
    "    train_augmented_gen, \n",
    "    epochs=20,\n",
    "    validation_data=valid_augmented_gen,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 5s 654ms/step - loss: 0.1575 - accuracy: 0.9410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.157472581602633, 0.941]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как видим точность еще выше примерно на 3 процента на одной и той же контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
